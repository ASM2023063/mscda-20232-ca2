{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05274a1a",
   "metadata": {},
   "source": [
    "# Title\n",
    "\n",
    "Continuous Assessment 2 10/11/2023 - BD & ADA Module // MSc in Data Analytics Y1 S2 - Student ID 2023063\n",
    "\n",
    "Data: ProjectsTweets.csv\n",
    "\n",
    "Github: https://github.com/ASM2023063/mscda-20232-ca2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2367fc5d",
   "metadata": {},
   "source": [
    "### 1. Research Understanding Phase \n",
    "\n",
    "\n",
    "### Draft rewrite description later\n",
    "- In this study an overarching analysis of Customer behavior in eCommerce shop was provided, preparing the customers’ event data for modeling and analysis to predict the number of purchases future customers will do.\n",
    "- PySparkSQL and TensorFlow were used in Jupyter Notebook file to complete this task, using SQL and Python coding language.\n",
    "- To perform an organized and clear understanding of the study timeline, Cross Industry Standard Process for Data Mining (CRISP-DM) Methodology was used, and the cells of code were grouped according to the methodology’s phases.\n",
    "- An Artificial Neural Network model was applied to the chosen variables X and y. For the evaluation phase Mean Absolute Error (MAE) and Mean Squared Error (MSE) were registered to measure the error between predicted and actual values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8179e9fc",
   "metadata": {},
   "source": [
    "### 2. Data Understanding Phase\n",
    "\n",
    "Practical Big Data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60dadde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import PySparkSQL\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession        \n",
    "\n",
    "# Create SparkSession with enableHiveSupport\n",
    "df = (SparkSession\n",
    "  .builder\n",
    "  .master(\"local[*]\")\n",
    "  .appName(\"SparkSQL\")\n",
    "  .enableHiveSupport() \n",
    "  .getOrCreate())\n",
    "\n",
    "# Path to dataset\n",
    "csv_file = \"file:////home/hduser/Downloads/2023063_CA2/ProjectTweets.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e45df9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Read and create a temporary view\n",
    "df = (spark.read.format(\"csv\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .option(\"header\", \"false\")\n",
    "  .load(csv_file)\n",
    "  .toDF(\"id\",\"number\",\"date\",\"query\",\"name\",\"body\"))\n",
    "df.createOrReplaceTempView(\"temp_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "266ed1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- number: long (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- query: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualise inferred schema\n",
    "data = spark.sql(\"SELECT * FROM temp_view\")\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e93cac4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+--------+---------------+--------------------+\n",
      "| id|    number|                date|   query|           name|                body|\n",
      "+---+----------+--------------------+--------+---------------+--------------------+\n",
      "|  0|1467810369|Mon Apr 06 22:19:...|NO_QUERY|_TheSpecialOne_|@switchfoot http:...|\n",
      "|  1|1467810672|Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|is upset that he ...|\n",
      "|  2|1467810917|Mon Apr 06 22:19:...|NO_QUERY|       mattycus|@Kenichan I dived...|\n",
      "|  3|1467811184|Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|my whole body fee...|\n",
      "|  4|1467811193|Mon Apr 06 22:19:...|NO_QUERY|         Karoli|@nationwideclass ...|\n",
      "+---+----------+--------------------+--------+---------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display 5 first rows\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b217dd69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-22 18:48:52,614 WARN conf.HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "2023-10-22 18:48:52,614 WARN conf.HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "2023-10-22 18:48:53,736 WARN metastore.ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0\n",
      "2023-10-22 18:48:53,736 WARN metastore.ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore hduser@127.0.1.1\n",
      "2023-10-22 18:48:53,886 WARN metastore.ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n",
      "2023-10-22 18:48:53,893 ERROR metastore.RetryingHMSHandler: AlreadyExistsException(message:Database projectdb already exists)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:925)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat com.sun.proxy.$Proxy23.create_database(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createDatabase(HiveMetaStoreClient.java:725)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:173)\n",
      "\tat com.sun.proxy.$Proxy24.createDatabase(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createDatabase(Hive.java:434)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$createDatabase$1(HiveClientImpl.scala:347)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:305)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:236)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:235)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:285)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.createDatabase(HiveClientImpl.scala:345)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$createDatabase$1(HiveExternalCatalog.scala:193)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.createDatabase(HiveExternalCatalog.scala:193)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.ExternalCatalogWithListener.createDatabase(ExternalCatalogWithListener.scala:47)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.createDatabase(SessionCatalog.scala:251)\n",
      "\tat org.apache.spark.sql.execution.command.CreateDatabaseCommand.run(ddl.scala:83)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:97)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:97)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:93)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:481)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:82)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:481)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:457)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:93)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:80)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:78)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:219)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create database\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS projectdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff038b83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-22 18:48:53,931 WARN analysis.ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "2023-10-22 18:48:54,135 WARN session.SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n",
      "2023-10-22 18:48:54,199 WARN conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist\n",
      "2023-10-22 18:48:54,199 WARN conf.HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "2023-10-22 18:48:54,199 WARN conf.HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "2023-10-22 18:48:54,209 ERROR metastore.RetryingHMSHandler: AlreadyExistsException(message:Table tweetstable already exists)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_table_core(HiveMetaStore.java:1416)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_table_with_environment_context(HiveMetaStore.java:1503)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat com.sun.proxy.$Proxy23.create_table_with_environment_context(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.create_table_with_environment_context(HiveMetaStoreClient.java:2396)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.create_table_with_environment_context(SessionHiveMetaStoreClient.java:93)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:750)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:738)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:173)\n",
      "\tat com.sun.proxy.$Proxy24.createTable(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:859)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:874)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$createTable$1(HiveClientImpl.scala:555)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:305)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:236)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:235)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:285)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.createTable(HiveClientImpl.scala:553)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$createTable$1(HiveExternalCatalog.scala:287)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.createTable(HiveExternalCatalog.scala:245)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.ExternalCatalogWithListener.createTable(ExternalCatalogWithListener.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.createTable(SessionCatalog.scala:376)\n",
      "\tat org.apache.spark.sql.execution.command.CreateTableCommand.run(tables.scala:167)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:97)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:97)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:93)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:481)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:82)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:481)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:457)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:93)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:80)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:78)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:219)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create table in database\n",
    "spark.sql(\"CREATE TABLE IF NOT EXISTS projectdb.tweetsTable (id Int, number long, date String, query String, name String, body String)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "893c6de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alocate data to hive database\n",
    "#spark.sql(\"INSERT INTO TABLE projectdb.tweetsTable SELECT * FROM temp_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "651eead9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------------------------+--------+---------------+-----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|id    |number    |date                        |query   |name           |body                                                                                                                                     |\n",
      "+------+----------+----------------------------+--------+---------------+-----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|816210|1551363506|Sat Apr 18 08:51:40 PDT 2009|NO_QUERY|prosario_2000  |@ctribe I hope you are having a great day.                                                                                               |\n",
      "|816211|1551363569|Sat Apr 18 08:51:39 PDT 2009|NO_QUERY|Chelsea_Volturi|@Boy_Kill_Boy Nope Just Bored Well Say That Most Of The Time The Usual                                                                   |\n",
      "|816212|1551363682|Sat Apr 18 08:51:41 PDT 2009|NO_QUERY|askbillmitchell|@marty0518 Sometimes? and just a little cryptic? LOL! I am just messing with you.  You are a good sport.                                 |\n",
      "|816213|1551363752|Sat Apr 18 08:51:41 PDT 2009|NO_QUERY|kendiixd       |so i guesss im not in coolifornia anymore how exiting                                                                                    |\n",
      "|816214|1551363844|Sat Apr 18 08:51:42 PDT 2009|NO_QUERY|ladycalypso    |@DaiLS I do that, too, but right now, it's the Radiant Dawn Soundtrack.                                                                  |\n",
      "|816215|1551363866|Sat Apr 18 08:51:43 PDT 2009|NO_QUERY|FindingAnswers |trendy topic - Record Store Day - just becuz a song has the word &quot;Lollipop&quot; in it, doesn't mean it's appropriate for children. |\n",
      "|816216|1551363911|Sat Apr 18 08:51:43 PDT 2009|NO_QUERY|HTwashere      |@firsttiger Real phone? i just read your blog on phones - they are not phones anymore                                                    |\n",
      "|816217|1551363926|Sat Apr 18 08:51:43 PDT 2009|NO_QUERY|kelliekano     |@Dragoncade I see you're delivering your daily dose of sunshine to the twitterverse!  Happy Saturday to ya...                            |\n",
      "|816218|1551363992|Sat Apr 18 08:51:44 PDT 2009|NO_QUERY|JoshMetz       |Hi Guys i'm new on here  Just wonder what I can use this for? I were trying/hoping that I could find the real Miley Cyrus                |\n",
      "|816219|1551364008|Sat Apr 18 08:51:44 PDT 2009|NO_QUERY|jeewillikers   |leaving for my hair appt!!!!                                                                                                             |\n",
      "+------+----------+----------------------------+--------+---------------+-----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display table content\n",
    "spark.sql(\"SELECT * FROM projectdb.tweetsTable\").show(10,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c34cb740",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|  total|\n",
      "+-------+\n",
      "|1600000|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of rows\n",
    "spark.sql(\"SELECT count(*) as total FROM projectdb.tweetsTable\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c421ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------+\n",
      "|count(DISTINCT id, number, date, query, name, body)|\n",
      "+---------------------------------------------------+\n",
      "|                                            1600000|\n",
      "+---------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9:=============================>                             (2 + 2) / 4]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Number of unique rows\n",
    "df2 = spark.sql(\"SELECT count(distinct *) FROM projectdb.tweetsTable\")\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65d018b",
   "metadata": {},
   "source": [
    "### 3. Data Preparation Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79f60bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import pyspark.sql.functions\n",
    "from pyspark.sql.functions import split, to_date, date_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe6b8afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variable \n",
    "tweet_data = spark.sql(\"SELECT * FROM projectdb.tweetsTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb6d2379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split column date into new columns\n",
    "tweet_data = tweet_data.withColumn(\"date_parts\", split(tweet_data[\"date\"],\" \"))\n",
    "\n",
    "tweet_data = tweet_data.withColumn(\"month\", tweet_data[\"date_parts\"][1])\n",
    "tweet_data = tweet_data.withColumn(\"day\", tweet_data[\"date_parts\"][2])\n",
    "tweet_data = tweet_data.withColumn(\"time\", tweet_data[\"date_parts\"][3])\n",
    "tweet_data = tweet_data.withColumn(\"year\", tweet_data[\"date_parts\"][5])\n",
    "tweet_data = tweet_data.withColumn(\"weekday\", tweet_data[\"date_parts\"][0])\n",
    "tweet_data = tweet_data.withColumn(\"timezone\", tweet_data[\"date_parts\"][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "331f122f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split new column time into new columns\n",
    "tweet_data = tweet_data.withColumn(\"time_format\", split(tweet_data[\"time\"],\":\"))\n",
    "\n",
    "tweet_data = tweet_data.withColumn(\"hour\", tweet_data[\"time_format\"][0])\n",
    "tweet_data = tweet_data.withColumn(\"minute\", tweet_data[\"time_format\"][1])\n",
    "tweet_data = tweet_data.withColumn(\"second\", tweet_data[\"time_format\"][2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18747be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "tweet_data = tweet_data.drop(\"date_parts\")\n",
    "tweet_data = tweet_data.drop(\"date\")\n",
    "tweet_data = tweet_data.drop(\"number\")\n",
    "tweet_data = tweet_data.drop(\"query\")\n",
    "tweet_data = tweet_data.drop(\"time_format\")\n",
    "tweet_data = tweet_data.drop(\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da051b05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+--------------------+-----+---+----+-------+--------+----+------+------+\n",
      "|    id|           name|                body|month|day|year|weekday|timezone|hour|minute|second|\n",
      "+------+---------------+--------------------+-----+---+----+-------+--------+----+------+------+\n",
      "|816210|  prosario_2000|@ctribe I hope yo...|  Apr| 18|2009|    Sat|     PDT|  08|    51|    40|\n",
      "|816211|Chelsea_Volturi|@Boy_Kill_Boy Nop...|  Apr| 18|2009|    Sat|     PDT|  08|    51|    39|\n",
      "|816212|askbillmitchell|@marty0518 Someti...|  Apr| 18|2009|    Sat|     PDT|  08|    51|    41|\n",
      "|816213|       kendiixd|so i guesss im no...|  Apr| 18|2009|    Sat|     PDT|  08|    51|    41|\n",
      "|816214|    ladycalypso|@DaiLS I do that,...|  Apr| 18|2009|    Sat|     PDT|  08|    51|    42|\n",
      "|816215| FindingAnswers|trendy topic - Re...|  Apr| 18|2009|    Sat|     PDT|  08|    51|    43|\n",
      "|816216|      HTwashere|@firsttiger Real ...|  Apr| 18|2009|    Sat|     PDT|  08|    51|    43|\n",
      "|816217|     kelliekano|@Dragoncade I see...|  Apr| 18|2009|    Sat|     PDT|  08|    51|    43|\n",
      "|816218|       JoshMetz|Hi Guys i'm new o...|  Apr| 18|2009|    Sat|     PDT|  08|    51|    44|\n",
      "|816219|   jeewillikers|leaving for my ha...|  Apr| 18|2009|    Sat|     PDT|  08|    51|    44|\n",
      "|816220|     reesypants|@reedoh Hello lov...|  Apr| 18|2009|    Sat|     PDT|  08|    51|    44|\n",
      "|816221|          Liveo|@redrobinrockn Yo...|  Apr| 18|2009|    Sat|     PDT|  08|    51|    45|\n",
      "|816222|          alpew|Exeter City take ...|  Apr| 18|2009|    Sat|     PDT|  08|    51|    45|\n",
      "|816223|     mallverine|@30comau I'll che...|  Apr| 18|2009|    Sat|     PDT|  08|    51|    46|\n",
      "|816224|     musicisme7|@taylorswift13 wh...|  Apr| 18|2009|    Sat|     PDT|  08|    51|    46|\n",
      "|816225|       megan901|@muhfukinchico ha...|  Apr| 18|2009|    Sat|     PDT|  08|    51|    47|\n",
      "|816226|        IsJonas|A big mean asshol...|  Apr| 18|2009|    Sat|     PDT|  08|    51|    46|\n",
      "|816227|         patrix|@jinadcruz @keith...|  Apr| 18|2009|    Sat|     PDT|  08|    51|    47|\n",
      "|816228|       Vielfras|Whoa, look what I...|  Apr| 18|2009|    Sat|     PDT|  08|    51|    48|\n",
      "|816229|     bekahkirby|Hiking grandfathe...|  Apr| 18|2009|    Sat|     PDT|  08|    51|    47|\n",
      "+------+---------------+--------------------+-----+---+----+-------+--------+----+------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check changes \n",
    "tweet_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e000de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis \n",
    "\n",
    "#!pip install vaderSentiment\n",
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8aeedad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "import nltk\n",
    "\n",
    "# Import the lexicon \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e01934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function  and create sentiment_score column\n",
    "def analyse_sentiment(body):\n",
    "    analyser = SentimentIntensityAnalyzer()\n",
    "    sentiment = analyser.polarity_scores(body)\n",
    "    return sentiment['compound']\n",
    "\n",
    "sentiment_udf = udf(analyse_sentiment, DoubleType())\n",
    "\n",
    "tweet_data = tweet_data.withColumn(\"sentiment_score\", sentiment_udf(tweet_data['body']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64da8dfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tweet_data.write.mode(\"overwrite\").saveAsTable(\"tweet_data2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1dc37688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New column polarity based on compound value\n",
    "tweet_data = tweet_data.withColumn(\"polarity\", when (tweet_data[\"sentiment_score\"]>= 0.05, \"positive\")\n",
    "                                                .when(tweet_data[\"sentiment_score\"]<=-0.05, \"negative\")\n",
    "                                                .otherwise(\"neutral\")\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f66f428a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 15:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+--------------------------------------------------------------------------------------------------------+-----+---+----+-------+--------+----+------+------+---------------+--------+\n",
      "|id    |name           |body                                                                                                    |month|day|year|weekday|timezone|hour|minute|second|sentiment_score|polarity|\n",
      "+------+---------------+--------------------------------------------------------------------------------------------------------+-----+---+----+-------+--------+----+------+------+---------------+--------+\n",
      "|816210|prosario_2000  |@ctribe I hope you are having a great day.                                                              |Apr  |18 |2009|Sat    |PDT     |08  |51    |40    |0.7906         |positive|\n",
      "|816211|Chelsea_Volturi|@Boy_Kill_Boy Nope Just Bored Well Say That Most Of The Time The Usual                                  |Apr  |18 |2009|Sat    |PDT     |08  |51    |39    |0.0            |neutral |\n",
      "|816212|askbillmitchell|@marty0518 Sometimes? and just a little cryptic? LOL! I am just messing with you.  You are a good sport.|Apr  |18 |2009|Sat    |PDT     |08  |51    |41    |0.7787         |positive|\n",
      "|816213|kendiixd       |so i guesss im not in coolifornia anymore how exiting                                                   |Apr  |18 |2009|Sat    |PDT     |08  |51    |41    |0.0            |neutral |\n",
      "|816214|ladycalypso    |@DaiLS I do that, too, but right now, it's the Radiant Dawn Soundtrack.                                 |Apr  |18 |2009|Sat    |PDT     |08  |51    |42    |0.631          |positive|\n",
      "+------+---------------+--------------------------------------------------------------------------------------------------------+-----+---+----+-------+--------+----+------+------+---------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Display data\n",
    "tweet_data.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "335d1cbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Plot graphs to visualise the sentiment score over time\n",
    "\n",
    "tweet_pandas = tweet_data.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e4597da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import pandas as pd\n",
    "\n",
    "# Plot by month\n",
    "# Convert month column to datetime object \n",
    "#tweet_pandas['month'] = pd.to_datetime(tweet_pandas['month'], format='%b')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7594499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_number(abbrev):\n",
    "    month_abbrev_to_number= {\n",
    "        'Jan':'01', \n",
    "        'Fev':'02', \n",
    "        'Mar':'03', \n",
    "        'Apr':'04', \n",
    "        'May':'05', \n",
    "        'Jun':'06', \n",
    "        'Jul':'07', \n",
    "        'Aug':'08', \n",
    "        'Sep':'09', \n",
    "        'Oct':'10', \n",
    "        'Nov':'11', \n",
    "        'Dec':'12'\n",
    "    } \n",
    "    return month_abbrev_to_number.get(abbrev, abbrev)\n",
    "\n",
    "tweet_pandas['month'] = tweet_pandas['month'].apply(convert_to_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "632073ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_pandas['month'] = tweet_pandas['month'].astype(int)\n",
    "tweet_pandas['day'] = tweet_pandas['day'].astype(int)\n",
    "tweet_pandas['year'] = tweet_pandas['year'].astype(int)\n",
    "tweet_pandas['hour'] = tweet_pandas['hour'].astype(int)\n",
    "tweet_pandas['minute'] = tweet_pandas['minute'].astype(int)\n",
    "tweet_pandas['second'] = tweet_pandas['second'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f21184f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count    Dtype  \n",
      "---  ------           --------------    -----  \n",
      " 0   id               1600000 non-null  int32  \n",
      " 1   name             1600000 non-null  object \n",
      " 2   body             1600000 non-null  object \n",
      " 3   month            1600000 non-null  int64  \n",
      " 4   day              1600000 non-null  int64  \n",
      " 5   year             1600000 non-null  int64  \n",
      " 6   weekday          1600000 non-null  object \n",
      " 7   timezone         1600000 non-null  object \n",
      " 8   hour             1600000 non-null  int64  \n",
      " 9   minute           1600000 non-null  int64  \n",
      " 10  second           1600000 non-null  int64  \n",
      " 11  sentiment_score  1600000 non-null  float64\n",
      " 12  polarity         1600000 non-null  object \n",
      "dtypes: float64(1), int32(1), int64(6), object(5)\n",
      "memory usage: 152.6+ MB\n"
     ]
    }
   ],
   "source": [
    "tweet_pandas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0ca9521",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_pandas['date']=pd.to_datetime(tweet_pandas[['year','month','day']], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e02a3dfc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>body</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>year</th>\n",
       "      <th>weekday</th>\n",
       "      <th>timezone</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>polarity</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>816210</td>\n",
       "      <td>prosario_2000</td>\n",
       "      <td>@ctribe I hope you are having a great day.</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>2009</td>\n",
       "      <td>Sat</td>\n",
       "      <td>PDT</td>\n",
       "      <td>8</td>\n",
       "      <td>51</td>\n",
       "      <td>40</td>\n",
       "      <td>0.7906</td>\n",
       "      <td>positive</td>\n",
       "      <td>2009-04-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>816211</td>\n",
       "      <td>Chelsea_Volturi</td>\n",
       "      <td>@Boy_Kill_Boy Nope Just Bored Well Say That Mo...</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>2009</td>\n",
       "      <td>Sat</td>\n",
       "      <td>PDT</td>\n",
       "      <td>8</td>\n",
       "      <td>51</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2009-04-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>816212</td>\n",
       "      <td>askbillmitchell</td>\n",
       "      <td>@marty0518 Sometimes? and just a little crypti...</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>2009</td>\n",
       "      <td>Sat</td>\n",
       "      <td>PDT</td>\n",
       "      <td>8</td>\n",
       "      <td>51</td>\n",
       "      <td>41</td>\n",
       "      <td>0.7787</td>\n",
       "      <td>positive</td>\n",
       "      <td>2009-04-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>816213</td>\n",
       "      <td>kendiixd</td>\n",
       "      <td>so i guesss im not in coolifornia anymore how ...</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>2009</td>\n",
       "      <td>Sat</td>\n",
       "      <td>PDT</td>\n",
       "      <td>8</td>\n",
       "      <td>51</td>\n",
       "      <td>41</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2009-04-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>816214</td>\n",
       "      <td>ladycalypso</td>\n",
       "      <td>@DaiLS I do that, too, but right now, it's the...</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>2009</td>\n",
       "      <td>Sat</td>\n",
       "      <td>PDT</td>\n",
       "      <td>8</td>\n",
       "      <td>51</td>\n",
       "      <td>42</td>\n",
       "      <td>0.6310</td>\n",
       "      <td>positive</td>\n",
       "      <td>2009-04-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             name                                               body  \\\n",
       "0  816210    prosario_2000        @ctribe I hope you are having a great day.    \n",
       "1  816211  Chelsea_Volturi  @Boy_Kill_Boy Nope Just Bored Well Say That Mo...   \n",
       "2  816212  askbillmitchell  @marty0518 Sometimes? and just a little crypti...   \n",
       "3  816213         kendiixd  so i guesss im not in coolifornia anymore how ...   \n",
       "4  816214      ladycalypso  @DaiLS I do that, too, but right now, it's the...   \n",
       "\n",
       "   month  day  year weekday timezone  hour  minute  second  sentiment_score  \\\n",
       "0      4   18  2009     Sat      PDT     8      51      40           0.7906   \n",
       "1      4   18  2009     Sat      PDT     8      51      39           0.0000   \n",
       "2      4   18  2009     Sat      PDT     8      51      41           0.7787   \n",
       "3      4   18  2009     Sat      PDT     8      51      41           0.0000   \n",
       "4      4   18  2009     Sat      PDT     8      51      42           0.6310   \n",
       "\n",
       "   polarity       date  \n",
       "0  positive 2009-04-18  \n",
       "1   neutral 2009-04-18  \n",
       "2  positive 2009-04-18  \n",
       "3   neutral 2009-04-18  \n",
       "4  positive 2009-04-18  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_pandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40b75efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by day and calculate the average sentiment score \n",
    "daily_sentiment = tweet_pandas.groupby('date')['sentiment_score'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092fc65c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7fdbb3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-04-06</td>\n",
       "      <td>0.142341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>0.161992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-04-17</td>\n",
       "      <td>0.198497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-04-18</td>\n",
       "      <td>0.180743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-04-19</td>\n",
       "      <td>0.184278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2009-04-20</td>\n",
       "      <td>0.172956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2009-04-21</td>\n",
       "      <td>0.174545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2009-05-01</td>\n",
       "      <td>0.177180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2009-05-02</td>\n",
       "      <td>0.180311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2009-05-03</td>\n",
       "      <td>0.172791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2009-05-04</td>\n",
       "      <td>0.163054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2009-05-09</td>\n",
       "      <td>0.182475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2009-05-10</td>\n",
       "      <td>0.213141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2009-05-11</td>\n",
       "      <td>0.165733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2009-05-13</td>\n",
       "      <td>0.141616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2009-05-14</td>\n",
       "      <td>0.167195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2009-05-16</td>\n",
       "      <td>0.173934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2009-05-17</td>\n",
       "      <td>0.201135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2009-05-18</td>\n",
       "      <td>0.187934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2009-05-21</td>\n",
       "      <td>0.175404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2009-05-22</td>\n",
       "      <td>0.197309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2009-05-23</td>\n",
       "      <td>0.188302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2009-05-25</td>\n",
       "      <td>0.180129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2009-05-26</td>\n",
       "      <td>0.170487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2009-05-27</td>\n",
       "      <td>0.125456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2009-05-28</td>\n",
       "      <td>0.185597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2009-05-29</td>\n",
       "      <td>0.183794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2009-05-30</td>\n",
       "      <td>0.191028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2009-05-31</td>\n",
       "      <td>0.192285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>0.172664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2009-06-02</td>\n",
       "      <td>0.173374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2009-06-03</td>\n",
       "      <td>0.171944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2009-06-04</td>\n",
       "      <td>0.161025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2009-06-05</td>\n",
       "      <td>0.182378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2009-06-06</td>\n",
       "      <td>0.180086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2009-06-07</td>\n",
       "      <td>0.181526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2009-06-14</td>\n",
       "      <td>0.171822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2009-06-15</td>\n",
       "      <td>0.165252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2009-06-16</td>\n",
       "      <td>0.078605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2009-06-17</td>\n",
       "      <td>-0.047918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2009-06-18</td>\n",
       "      <td>-0.051820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2009-06-19</td>\n",
       "      <td>-0.046075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2009-06-20</td>\n",
       "      <td>-0.039213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2009-06-21</td>\n",
       "      <td>-0.026631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2009-06-22</td>\n",
       "      <td>-0.064475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2009-06-23</td>\n",
       "      <td>-0.052387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2009-06-24</td>\n",
       "      <td>-0.046640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2009-06-25</td>\n",
       "      <td>-0.053316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  sentiment_score\n",
       "0  2009-04-06         0.142341\n",
       "1  2009-04-07         0.161992\n",
       "2  2009-04-17         0.198497\n",
       "3  2009-04-18         0.180743\n",
       "4  2009-04-19         0.184278\n",
       "5  2009-04-20         0.172956\n",
       "6  2009-04-21         0.174545\n",
       "7  2009-05-01         0.177180\n",
       "8  2009-05-02         0.180311\n",
       "9  2009-05-03         0.172791\n",
       "10 2009-05-04         0.163054\n",
       "11 2009-05-09         0.182475\n",
       "12 2009-05-10         0.213141\n",
       "13 2009-05-11         0.165733\n",
       "14 2009-05-13         0.141616\n",
       "15 2009-05-14         0.167195\n",
       "16 2009-05-16         0.173934\n",
       "17 2009-05-17         0.201135\n",
       "18 2009-05-18         0.187934\n",
       "19 2009-05-21         0.175404\n",
       "20 2009-05-22         0.197309\n",
       "21 2009-05-23         0.188302\n",
       "22 2009-05-25         0.180129\n",
       "23 2009-05-26         0.170487\n",
       "24 2009-05-27         0.125456\n",
       "25 2009-05-28         0.185597\n",
       "26 2009-05-29         0.183794\n",
       "27 2009-05-30         0.191028\n",
       "28 2009-05-31         0.192285\n",
       "29 2009-06-01         0.172664\n",
       "30 2009-06-02         0.173374\n",
       "31 2009-06-03         0.171944\n",
       "32 2009-06-04         0.161025\n",
       "33 2009-06-05         0.182378\n",
       "34 2009-06-06         0.180086\n",
       "35 2009-06-07         0.181526\n",
       "36 2009-06-14         0.171822\n",
       "37 2009-06-15         0.165252\n",
       "38 2009-06-16         0.078605\n",
       "39 2009-06-17        -0.047918\n",
       "40 2009-06-18        -0.051820\n",
       "41 2009-06-19        -0.046075\n",
       "42 2009-06-20        -0.039213\n",
       "43 2009-06-21        -0.026631\n",
       "44 2009-06-22        -0.064475\n",
       "45 2009-06-23        -0.052387\n",
       "46 2009-06-24        -0.046640\n",
       "47 2009-06-25        -0.053316"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aa5afd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = {\n",
    "    \n",
    "    'date': pd.date_range(start='2009-04-06', end='2009-06-25', freq='D'),\n",
    "    'sentiment_score': None\n",
    "}\n",
    "\n",
    "newdf_daily_merge = pd.DataFrame(newdf)\n",
    "newdf_daily_merge.set_index('date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "28f4ce95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-04-06</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-08</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-09</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-10</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-11</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-12</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-13</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-14</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-15</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-16</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-17</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-18</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-19</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-20</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-21</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-22</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-23</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-24</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-25</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-26</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-27</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-28</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-29</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-30</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-01</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-02</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-03</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-04</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-05</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-06</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-07</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-08</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-09</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-10</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-11</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-12</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-13</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-14</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-15</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-16</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-17</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-18</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-19</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-20</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-21</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-22</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-23</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-24</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-25</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-26</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-27</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-28</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-29</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-30</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-31</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-01</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-02</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-03</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-04</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-05</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-06</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-07</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-08</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-09</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-10</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-11</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-12</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-13</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-14</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-15</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-16</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-17</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-18</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-19</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-20</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-21</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-22</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-23</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-24</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-25</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sentiment_score\n",
       "date                      \n",
       "2009-04-06            None\n",
       "2009-04-07            None\n",
       "2009-04-08            None\n",
       "2009-04-09            None\n",
       "2009-04-10            None\n",
       "2009-04-11            None\n",
       "2009-04-12            None\n",
       "2009-04-13            None\n",
       "2009-04-14            None\n",
       "2009-04-15            None\n",
       "2009-04-16            None\n",
       "2009-04-17            None\n",
       "2009-04-18            None\n",
       "2009-04-19            None\n",
       "2009-04-20            None\n",
       "2009-04-21            None\n",
       "2009-04-22            None\n",
       "2009-04-23            None\n",
       "2009-04-24            None\n",
       "2009-04-25            None\n",
       "2009-04-26            None\n",
       "2009-04-27            None\n",
       "2009-04-28            None\n",
       "2009-04-29            None\n",
       "2009-04-30            None\n",
       "2009-05-01            None\n",
       "2009-05-02            None\n",
       "2009-05-03            None\n",
       "2009-05-04            None\n",
       "2009-05-05            None\n",
       "2009-05-06            None\n",
       "2009-05-07            None\n",
       "2009-05-08            None\n",
       "2009-05-09            None\n",
       "2009-05-10            None\n",
       "2009-05-11            None\n",
       "2009-05-12            None\n",
       "2009-05-13            None\n",
       "2009-05-14            None\n",
       "2009-05-15            None\n",
       "2009-05-16            None\n",
       "2009-05-17            None\n",
       "2009-05-18            None\n",
       "2009-05-19            None\n",
       "2009-05-20            None\n",
       "2009-05-21            None\n",
       "2009-05-22            None\n",
       "2009-05-23            None\n",
       "2009-05-24            None\n",
       "2009-05-25            None\n",
       "2009-05-26            None\n",
       "2009-05-27            None\n",
       "2009-05-28            None\n",
       "2009-05-29            None\n",
       "2009-05-30            None\n",
       "2009-05-31            None\n",
       "2009-06-01            None\n",
       "2009-06-02            None\n",
       "2009-06-03            None\n",
       "2009-06-04            None\n",
       "2009-06-05            None\n",
       "2009-06-06            None\n",
       "2009-06-07            None\n",
       "2009-06-08            None\n",
       "2009-06-09            None\n",
       "2009-06-10            None\n",
       "2009-06-11            None\n",
       "2009-06-12            None\n",
       "2009-06-13            None\n",
       "2009-06-14            None\n",
       "2009-06-15            None\n",
       "2009-06-16            None\n",
       "2009-06-17            None\n",
       "2009-06-18            None\n",
       "2009-06-19            None\n",
       "2009-06-20            None\n",
       "2009-06-21            None\n",
       "2009-06-22            None\n",
       "2009-06-23            None\n",
       "2009-06-24            None\n",
       "2009-06-25            None"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf_daily_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "79a33f35",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['date'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10168/3955776506.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdaily_sentiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mset_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   5871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5872\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5873\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of {missing} are in the columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5875\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of ['date'] are in the columns\""
     ]
    }
   ],
   "source": [
    "daily_sentiment.set_index('date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "243e569d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-04-06</th>\n",
       "      <td>0.142341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07</th>\n",
       "      <td>0.161992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-08</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-09</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-10</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sentiment_score\n",
       "date                      \n",
       "2009-04-06        0.142341\n",
       "2009-04-07        0.161992\n",
       "2009-04-08             NaN\n",
       "2009-04-09             NaN\n",
       "2009-04-10             NaN"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf_daily_merge = newdf_daily_merge.combine_first(daily_sentiment)\n",
    " \n",
    "pd.set_option('display.max_rows', None)\n",
    "newdf_daily_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "622adc35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-05-01</th>\n",
       "      <td>0.17718</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-02</th>\n",
       "      <td>0.180311</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-03</th>\n",
       "      <td>0.172791</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-04</th>\n",
       "      <td>0.163054</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sentiment_score   weekday\n",
       "date                                \n",
       "2009-05-01         0.17718    Friday\n",
       "2009-05-02        0.180311  Saturday\n",
       "2009-05-03        0.172791    Sunday\n",
       "2009-05-04        0.163054    Monday\n",
       "2009-05-05             NaN   Tuesday"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf_daily_merge['weekday']=newdf_daily_merge.index.day_name()\n",
    "newdf_daily_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bdcfd544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-05-01</th>\n",
       "      <td>0.17718</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-02</th>\n",
       "      <td>0.180311</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-03</th>\n",
       "      <td>0.172791</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-04</th>\n",
       "      <td>0.163054</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sentiment_score   weekday\n",
       "date                                \n",
       "2009-05-01         0.17718    Friday\n",
       "2009-05-02        0.180311  Saturday\n",
       "2009-05-03        0.172791    Sunday\n",
       "2009-05-04        0.163054    Monday\n",
       "2009-05-05             NaN   Tuesday"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf_daily_merge = newdf_daily_merge[~(newdf_daily_merge.index.month==4)]\n",
    "newdf_daily_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5a0a53",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aa21a2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to input sentiment_score to NaN\n",
    "# The NaN value will be replaced with the mean value between the day before and the day after. \n",
    "\n",
    "\n",
    "def fill_nan_with_mean(df, date_to_fill, column_name):\n",
    "    date_to_fill = pd.to_datetime(date_to_fill)\n",
    "    \n",
    "    if date_to_fill in df.index:\n",
    "        mean_value = df.loc[date_to_fill - pd.DateOffset(days=1):date_to_fill+pd.DateOffset(days=1),column_name].mean()\n",
    "        \n",
    "        df.at[date_to_fill, column_name] = mean_value\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3d68095f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-05-01</th>\n",
       "      <td>0.17718</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-02</th>\n",
       "      <td>0.180311</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-03</th>\n",
       "      <td>0.172791</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-04</th>\n",
       "      <td>0.163054</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-08</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-09</th>\n",
       "      <td>0.182475</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-10</th>\n",
       "      <td>0.213141</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-11</th>\n",
       "      <td>0.165733</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-12</th>\n",
       "      <td>0.153675</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-13</th>\n",
       "      <td>0.141616</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-14</th>\n",
       "      <td>0.167195</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-15</th>\n",
       "      <td>0.170564</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-16</th>\n",
       "      <td>0.173934</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-17</th>\n",
       "      <td>0.201135</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-18</th>\n",
       "      <td>0.187934</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-21</th>\n",
       "      <td>0.175404</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-22</th>\n",
       "      <td>0.197309</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-23</th>\n",
       "      <td>0.188302</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-24</th>\n",
       "      <td>0.184215</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-25</th>\n",
       "      <td>0.180129</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-26</th>\n",
       "      <td>0.170487</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-27</th>\n",
       "      <td>0.125456</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-28</th>\n",
       "      <td>0.185597</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-29</th>\n",
       "      <td>0.183794</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-30</th>\n",
       "      <td>0.191028</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-31</th>\n",
       "      <td>0.192285</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-01</th>\n",
       "      <td>0.172664</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-02</th>\n",
       "      <td>0.173374</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-03</th>\n",
       "      <td>0.171944</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-04</th>\n",
       "      <td>0.161025</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-05</th>\n",
       "      <td>0.182378</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-06</th>\n",
       "      <td>0.180086</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-07</th>\n",
       "      <td>0.181526</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-08</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-09</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-14</th>\n",
       "      <td>0.171822</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-15</th>\n",
       "      <td>0.165252</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-16</th>\n",
       "      <td>0.078605</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-17</th>\n",
       "      <td>-0.047918</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-18</th>\n",
       "      <td>-0.05182</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-19</th>\n",
       "      <td>-0.046075</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-20</th>\n",
       "      <td>-0.039213</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-21</th>\n",
       "      <td>-0.026631</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-22</th>\n",
       "      <td>-0.064475</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-23</th>\n",
       "      <td>-0.052387</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-24</th>\n",
       "      <td>-0.04664</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-25</th>\n",
       "      <td>-0.053316</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sentiment_score    weekday\n",
       "date                                 \n",
       "2009-05-01         0.17718     Friday\n",
       "2009-05-02        0.180311   Saturday\n",
       "2009-05-03        0.172791     Sunday\n",
       "2009-05-04        0.163054     Monday\n",
       "2009-05-05             NaN    Tuesday\n",
       "2009-05-06             NaN  Wednesday\n",
       "2009-05-07             NaN   Thursday\n",
       "2009-05-08             NaN     Friday\n",
       "2009-05-09        0.182475   Saturday\n",
       "2009-05-10        0.213141     Sunday\n",
       "2009-05-11        0.165733     Monday\n",
       "2009-05-12        0.153675    Tuesday\n",
       "2009-05-13        0.141616  Wednesday\n",
       "2009-05-14        0.167195   Thursday\n",
       "2009-05-15        0.170564     Friday\n",
       "2009-05-16        0.173934   Saturday\n",
       "2009-05-17        0.201135     Sunday\n",
       "2009-05-18        0.187934     Monday\n",
       "2009-05-19             NaN    Tuesday\n",
       "2009-05-20             NaN  Wednesday\n",
       "2009-05-21        0.175404   Thursday\n",
       "2009-05-22        0.197309     Friday\n",
       "2009-05-23        0.188302   Saturday\n",
       "2009-05-24        0.184215     Sunday\n",
       "2009-05-25        0.180129     Monday\n",
       "2009-05-26        0.170487    Tuesday\n",
       "2009-05-27        0.125456  Wednesday\n",
       "2009-05-28        0.185597   Thursday\n",
       "2009-05-29        0.183794     Friday\n",
       "2009-05-30        0.191028   Saturday\n",
       "2009-05-31        0.192285     Sunday\n",
       "2009-06-01        0.172664     Monday\n",
       "2009-06-02        0.173374    Tuesday\n",
       "2009-06-03        0.171944  Wednesday\n",
       "2009-06-04        0.161025   Thursday\n",
       "2009-06-05        0.182378     Friday\n",
       "2009-06-06        0.180086   Saturday\n",
       "2009-06-07        0.181526     Sunday\n",
       "2009-06-08             NaN     Monday\n",
       "2009-06-09             NaN    Tuesday\n",
       "2009-06-10             NaN  Wednesday\n",
       "2009-06-11             NaN   Thursday\n",
       "2009-06-12             NaN     Friday\n",
       "2009-06-13             NaN   Saturday\n",
       "2009-06-14        0.171822     Sunday\n",
       "2009-06-15        0.165252     Monday\n",
       "2009-06-16        0.078605    Tuesday\n",
       "2009-06-17       -0.047918  Wednesday\n",
       "2009-06-18        -0.05182   Thursday\n",
       "2009-06-19       -0.046075     Friday\n",
       "2009-06-20       -0.039213   Saturday\n",
       "2009-06-21       -0.026631     Sunday\n",
       "2009-06-22       -0.064475     Monday\n",
       "2009-06-23       -0.052387    Tuesday\n",
       "2009-06-24        -0.04664  Wednesday\n",
       "2009-06-25       -0.053316   Thursday"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use function to input sentiment_score when there is only a single day with NaN\n",
    "\n",
    "newdf_daily_merge = fill_nan_with_mean(newdf_daily_merge, '2009-05-12', 'sentiment_score')\n",
    "newdf_daily_merge = fill_nan_with_mean(newdf_daily_merge, '2009-05-15', 'sentiment_score')\n",
    "newdf_daily_merge = fill_nan_with_mean(newdf_daily_merge, '2009-05-24', 'sentiment_score')\n",
    "\n",
    "newdf_daily_merge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c727a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a9c0dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15176838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e8f992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2230d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "eaa3242a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'docstring' from 'matplotlib' (/home/hduser/.local/lib/python3.10/site-packages/matplotlib/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10168/2297655986.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdaily_sentiment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdaily_sentiment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m from matplotlib.backend_bases import (\n\u001b[1;32m     65\u001b[0m     FigureCanvasBase, FigureManagerBase, MouseButton)\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFigureBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigaspect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgridspec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGridSpec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSubplotSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrcsetup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcParamsDefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcParamsOrig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_blocking_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend_bases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_docstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprojections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m from matplotlib.artist import (\n\u001b[1;32m     45\u001b[0m     Artist, allow_rasterization, _finalize_rasterization)\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgeo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAitoffAxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHammerAxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLambertAxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMollweideAxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpolar\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPolarAxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmpl_toolkits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmplot3d\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAxes3D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/mpl_toolkits/mplot3d/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0maxes3d\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAxes3D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3/dist-packages/mpl_toolkits/mplot3d/axes3d.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_preprocess_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martist\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmartist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmaxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'docstring' from 'matplotlib' (/home/hduser/.local/lib/python3.10/site-packages/matplotlib/__init__.py)"
     ]
    }
   ],
   "source": [
    "# Import library\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6));\n",
    "ax.plot(daily_sentiment['date'].to_numpy(), daily_sentiment['sentiment_score'].to_numpy());\n",
    "ax.set_xlabel('date');\n",
    "ax.set_ylabel('Compound');\n",
    "ax.grid();\n",
    "ax.tick_params(axis='x',rotation=45);\n",
    "\n",
    "ax.set_title('Sentiment score (compound) vs. Date');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87410595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb72cd3f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "daily_sentiment.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea778a8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "daily_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38990cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "daily_sentiment.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93045eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#daily_sentiment = daily_sentiment.resample('D').mean()\n",
    "result = seasonal_decompose(daily_sentiment['sentiment_score'], model='additive')\n",
    "\n",
    "trend = result.trend\n",
    "seasonal =result.seasonal\n",
    "residual = result.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef83c37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
